{
  "label": "Module 4: Vision-Language-Action (VLA)",
  "position": 6,
  "link": {
    "type": "generated-index",
    "description": "Enable natural human-robot interaction through vision-language-action models for embodied AI."
  },
  "customProps": {
    "learningObjectives": [
      "Understand VLA architecture and components",
      "Implement vision models for scene understanding",
      "Integrate language models for instruction following",
      "Generate robotic actions from natural language"
    ],
    "prerequisites": [
      "All previous modules completed",
      "Deep learning fundamentals",
      "Experience with transformers/LLMs"
    ],
    "estimatedHours": 16,
    "difficulty": "advanced"
  }
}
